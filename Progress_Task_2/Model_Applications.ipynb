{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <div style=\"border: 3px solid #FFFFF; padding: 10px; border-radius: 5px; background-color: #4484c2; text-align: center;\">Progress Task 2 (Machine Learning Model Applications and Analysis)</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is a summary of the work done in this second task. We will describe briefly the preprocessing steps, the models used and their performance in the competition and the lessons we have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 3px solid #FFFFF; padding: 10px; border-radius: 5px; background-color: #0096FF; text-align: center;\">FINAL POSITION</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have tested several models for this task, a Neural Network, a Random Forest and a KNN model. More specifically the implementations used were:\n",
    "* For the neural network:\n",
    "  * A normal Keras model, with 3 hidden layers.\n",
    "  * Using a combination of `scikit-learn`'s `RandomSearchCV` model, and a Keras model, to try to find the optimal hyperparameters for the network\n",
    "  * `MLPClassifier`, a neural network implementation found in `scikit-learn`, instead of being taken from an external library like Keras.\n",
    "* A Random Forest Model, developed using `scikit-learn`'s implementation. This model was the one with the best performance.\n",
    "* KNN model <!-- TODO Not read this one, fill this in -->\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <div style=\"border: 3px solid #FFFFF; padding: 10px; border-radius: 5px; background-color: #4484c2;\">Methodology</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **First attempt.** Random Forest 0.8520\n",
    "\n",
    "The first thing we did was inspecting the dataset and we realize that it had too many null values. Then, we decided to delete the rows that had these values since the dataset was so large that deleting a few rows wouldn't affect the training.  \n",
    "\n",
    "**We were wrong.**\n",
    "\n",
    "When we tried to do the same with the test dataset, we realized that we couldnâ€™t simply ignore the null values and that we needed to handle them properly. For the treatment of nulls in categorical variables, we assigned a new category called 'missing,' and for numerical values, we used -1.\n",
    "Later we removed some variables that seemed useless employment_industry or hhs_geo and encode both the training and test set using OrdinalEncoder. This is how we obtained the first dataset. After that, we needed to choose a model. \n",
    "\n",
    "Based on the results from the first task, we decided to try Random Forest with hyperparameter search, as it was the best among all the classifiers. \n",
    "\n",
    "**Result on competition: 0.8520** around 800th place which was around the middle of the leaderboard. Not bad for being the first attempt.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Trying to improve our ranking**\n",
    "\n",
    "To improve our ranking, we decided to follow two approaches: one would explore more Random Forest, and the other would investigate other models.\n",
    "\n",
    "**1. Other models**\n",
    "\n",
    "One teammate tried MLPClassifer as an inital approach to Neural Networks while other implemented a complete pipeline using Keras. The third one, tried KNN, but it didn't improve on the Random Forest results. In addition, KNN is influenced by class imbalance and outliers, and we haven't addressed these issues in the dataset.\n",
    "\n",
    "**Result on competition: 0.8487 for MLPClassifier**  \n",
    "**Result on competition: 0.8464 for Neural Networks**, we had some issues with this model.  \n",
    "**Result on competition: NOT tried for KNN**  \n",
    "\n",
    "**2. Random Forest**\n",
    "\n",
    "We already had a satisfactory result with Random Forest, but we wondered if it could be improved. Since we decided not to fix any random states, we were able to run the tests multiple times and obtain very different results, which we saved in MLflow.\n",
    "\n",
    "We tried several approaches:\n",
    "\n",
    "- Running two separate Random Forest models, one for each target, and optimizing them independently instead of using a multi-output model.\n",
    "- We also tried filtering the dataset for each target, using only the features relevant to that target. However, this approach performed much worse, as we lost relationships between the features.\n",
    "- Finally, seeing that all of this was insufficient, we decided to use a \"retraining\" method on our initial approach. This improved performance, but only slightly.\n",
    "\n",
    "We will no longer work with Random Forest as we have run out of ideas.\n",
    "\n",
    "**Result on competition: 0.8538** with the best local Random Forest. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **What's next?: Use AI**\n",
    "\n",
    "We thought we had reached the limit with our approach, but to our surprise, the other teams were making significant improvements. We realized that we could also enhance our ranking by using all the tools available to us: Chat GPT.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Keras & RandomSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
