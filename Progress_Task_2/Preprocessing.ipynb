{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning 2024/2025 - Progress Task 2 (Data Preprocessing)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Statement for the task:**\n",
    "\n",
    "In this competition-style task, your objective is to build a predictive model that estimates the likelihood of individuals receiving two different vaccines: the H1N1 flu vaccine and the seasonal flu vaccine. You will create two separate probability predictions for each individual in the dataset: \n",
    "- h1n1_vaccine: The probability that an individual receives the H1N1 flu vaccine. \n",
    "- seasonal_vaccine: The probability that an individual receives the seasonal flu vaccine. \n",
    "\n",
    "All the information about the task is on the following site: \n",
    "https://www.drivendata.org/competitions/66/flu-shot-learning/page/210/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation of Environmental Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA = 'data/'\n",
    "train_features = pd.read_csv(PATH_DATA + 'training_set_features.csv')\n",
    "train_labels = pd.read_csv(PATH_DATA + 'training_set_labels.csv')\n",
    "test_features = pd.read_csv(PATH_DATA + 'test_set_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "Let's focus first on training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check dataset columns, and dytpes for features\n",
    "train_features.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at this summary of the dataset info, we can see that there are different values for Non-Null count for each column. This means that there are missing values in the dataset. We will have to deal with them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first 3 rows of the dataset\n",
    "train_features.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check labels dataset\n",
    "train_labels.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label description from the competition site:\n",
    "\n",
    "- h1n1_vaccine - Whether respondent received H1N1 flu vaccine.\n",
    "- seasonal_vaccine - Whether respondent received seasonal flu vaccine.\n",
    "\n",
    "Both are binary variables: 0 = No; 1 = Yes. Some respondents didn't get either vaccine, others got only one, and some got both. This is formulated as a multilabel (and not multiclass) problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that both datasets share one column, which is `respondent_id`. This column is the unique identifier for each respondent is use to relate the two datasets. We will set this column as the index for both datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the ID as index\n",
    "train_features.set_index('respondent_id', inplace=True)\n",
    "train_labels.set_index('respondent_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=================== SHAPE =====================\")\n",
    "print(\"Features (people, features): \",train_features.shape)\n",
    "print(\"Labels   (people, labels):   \",train_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we will merge both datasets into one, so we can have all the information in one place and not having to deal with several variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients = pd.concat([train_features, train_labels], axis=1)\n",
    "# Check that the columns are concatenated\n",
    "df_patients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of h1n1_vaccine and seasonal_vaccine\n",
    "# Group the labels into 00, 01, 10, 11\n",
    "df_patients['vaccine_group'] = df_patients['h1n1_vaccine'].astype(str) + df_patients['seasonal_vaccine'].astype(str)\n",
    "\n",
    "# Plot the distribution of the vaccine groups\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(x='vaccine_group', data=df_patients, order=['00', '01', '10', '11'], stat='percent')\n",
    "plt.xlabel('Vaccine Group')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of Vaccine Groups')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Null values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: this section should not be changed. Null values can't be dropped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = df_patients.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (null / len(df_patients)) * 100\n",
    "\n",
    "# Plot the missing values\n",
    "plt.figure(figsize=(16, 7))\n",
    "colors = ['red' if val > 20 else 'orange' for val in missing_percentage.values]\n",
    "sns.barplot(x=missing_percentage.index, y=missing_percentage.values, palette=colors, hue=missing_percentage.index, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage of Missing Values')\n",
    "plt.xlabel('Features')\n",
    "plt.title('Percentage of Missing Values by Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to explore the top 3 columns with the most missing values:\n",
    "* employment_industry\n",
    "* employment_occupation\n",
    "* health_insurance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients['employment_industry'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients['employment_occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop columns with no information\n",
    "# df_patients.drop(columns = ['employment_industry', 'employment_occupation'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"original values: \", df_patients['health_insurance'].unique()) # 0 = no, 1 = yes, na = unknown--> change to 2\n",
    "# df_patients['health_insurance'] = df_patients['health_insurance'].fillna(2)\n",
    "# print(\"new values: \", df_patients['health_insurance'].unique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = df_patients.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (null / len(df_patients)) * 100\n",
    "\n",
    "# Plot the missing values\n",
    "plt.figure(figsize=(16, 7))\n",
    "colors = ['red' if val > 20 else 'orange' for val in missing_percentage.values]\n",
    "sns.barplot(x=missing_percentage.index, y=missing_percentage.values, palette=colors, hue=missing_percentage.index, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage of Missing Values')\n",
    "plt.xlabel('Features')\n",
    "plt.title('Percentage of Missing Values by Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients['income_poverty'].unique() #?? al medio o a donde?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patients.dropna(subset=['income_poverty'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = df_patients.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (null / len(df_patients)) * 100\n",
    "\n",
    "# Plot the missing values\n",
    "plt.figure(figsize=(16, 7))\n",
    "colors = ['red' if val > 20 else 'orange' for val in missing_percentage.values]\n",
    "sns.barplot(x=missing_percentage.index, y=missing_percentage.values, palette=colors, hue=missing_percentage.index, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage of Missing Values')\n",
    "plt.xlabel('Features')\n",
    "plt.title('Percentage of Missing Values by Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_patients.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = df_patients.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = df_patients.select_dtypes(include=['object']).columns\n",
    "\n",
    "df_patients[float_columns]=df_patients[float_columns].fillna(-1)\n",
    "df_patients[categorical_columns]=df_patients[categorical_columns].fillna('missing')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the dataframe to include only float features\n",
    "float_features = df_patients.select_dtypes(include=['float64'])\n",
    "\n",
    "# Calculate the correlation matrix\n",
    "correlation_matrix = float_features.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(16, 12))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Matrix for Float Features')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check here for all the categorical data, to see if there is something wrong, or that we need to transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df_patients.select_dtypes(include=['object']).columns\n",
    "\n",
    "for i in cat_features:\n",
    "    print(i, end=\": \")\n",
    "    print(df_patients[i].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, there seems to be a column with no useful data, so we can start by removing that one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_patients.drop(columns=['hhs_geo_region', 'employment_industry', 'employment_occupation'], inplace=True)\n",
    "cat_features = df_patients.select_dtypes(include=['object']).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform columns from object type to categorical type, with order information baked in\n",
    "\n",
    "df_patients[\"age_group\"] = pd.Categorical(\n",
    "    df_patients[\"age_group\"],\n",
    "    categories=[\n",
    "        \"missing\",\n",
    "        \"18 - 34 Years\",\n",
    "        \"35 - 44 Years\",\n",
    "        \"45 - 54 Years\",\n",
    "        \"55 - 64 Years\",\n",
    "        \"65+ Years\"\n",
    "    ],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df_patients[\"education\"] = pd.Categorical(\n",
    "    df_patients[\"education\"],\n",
    "    categories=[\"missing\",\"< 12 Years\", \"12 Years\", \"Some College\", \"College Graduate\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df_patients[\"race\"] = pd.Categorical(\n",
    "    df_patients[\"race\"],\n",
    "    categories=[\"missing\", \"White\", \"Black\", \"Hispanic\", \"Other or Multiple\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df_patients[\"sex\"] = pd.Categorical(\n",
    "    df_patients[\"sex\"], categories=[\"missing\", \"Female\", \"Male\"], ordered=True\n",
    ")\n",
    "\n",
    "df_patients[\"income_poverty\"] = pd.Categorical(\n",
    "    df_patients[\"income_poverty\"],\n",
    "    categories=[\"missing\",\"Below Poverty\", \"<= $75,000, Above Poverty\", \"> $75,000\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df_patients[\"marital_status\"] = pd.Categorical(\n",
    "    df_patients[\"marital_status\"], categories=[\"misisng\", \"Not Married\", \"Married\"], ordered=True\n",
    ")\n",
    "\n",
    "df_patients[\"rent_or_own\"] = pd.Categorical(\n",
    "    df_patients[\"rent_or_own\"], categories=[\"missing\", \"Rent\", \"Own\"], ordered=True\n",
    ")\n",
    "\n",
    "df_patients[\"employment_status\"] = pd.Categorical(\n",
    "    df_patients[\"employment_status\"],\n",
    "    categories=[\"missing\",\"Not in Labor Force\", \"Employed\", \"Unemployed\"],\n",
    "    ordered=True,\n",
    ")\n",
    "\n",
    "df_patients[\"census_msa\"] = pd.Categorical(\n",
    "    df_patients[\"census_msa\"],\n",
    "    categories=[\"Non-MSA\", \"MSA, Not Principle  City\", \"MSA, Principle City\", \"missing\"],\n",
    "    ordered=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also transform some columns from their string representation, into something easier to process, like changing the rent_or_own to owns_home and use 0 or 1. Maybe it is not necesary? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check if useful in next class\n",
    "# Convert the categorical columns to numerical in rent_or_own and rename the column as owns_home\n",
    "# df_patients['rent_or_own_n'] = df_patients['rent_or_own'].replace({'Own': 1, 'Rent': 0})\n",
    "\n",
    "# df_patients['marital_status_n'] = df_patients['marital_status'].replace({'Not Married': 0, 'Married': 1})\n",
    "\n",
    "# df_patients['education_n'] = df_patients['education'].replace({'< 12 Years': 0, '12 Years': 1, 'Some College': 2, 'College Graduate': 3})\n",
    "\n",
    "# df_patients['income_poverty_n'] =  df_patients['income_poverty'].replace({'Below Poverty': 0, '<= $75,000, Above Poverty': 1, '> $75,000': 2})\n",
    "\n",
    "# df_patients['age_group_n'] = df_patients['age_group'].replace({'18 - 34 Years': 0, '35 - 44 Years': 1, '45 - 54 Years': 2, '55 - 64 Years': 3, '65+ Years': 4})\n",
    "\n",
    "# # race, sex employment_status and census_msa\n",
    "# df_patients['race'] = df_patients['race'].replace({'White': 0, 'Black': 1, 'Hispanic': 2, 'Other or Multiple': 3})\n",
    "\n",
    "# df_patients['sex'] = df_patients['sex'].replace({'Female':0, 'Male':1})\n",
    "\n",
    "# df_patients['employment_status'] = df_patients['employment_status'].replace({'Not in Labor Force': 0, 'Employed': 1, 'Unemployed': 2})\n",
    "\n",
    "# df_patients['census_msa'] = df_patients['census_msa'].replace({'Non-MSA': 0, 'MSA, Not Principle  City': 1, 'MSA, Principle City': 2})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "\n",
    "\n",
    "for i in cat_features:\n",
    "\n",
    "    # Plot the stacked bar plot\n",
    "    fig:Figure; cont_table_ax:Axes; cont_table_ax_n:Axes\n",
    "    fig, (cont_table_ax, cont_table_ax_n) = plt.subplots(1, 2)\n",
    "    \n",
    "    cont_table = pd.crosstab(df_patients[i], df_patients['vaccine_group'],normalize='all') * 100\n",
    "    cont_table.plot(kind='bar', stacked=True, figsize=(10, 6),ax=cont_table_ax)\n",
    "    cont_table_n = pd.crosstab(df_patients[i], df_patients['vaccine_group'],normalize='index') * 100\n",
    "    cont_table_n.plot(kind='bar', stacked=True, figsize=(10, 6),ax=cont_table_ax_n)\n",
    "\n",
    "    cont_table_ax.set_xlabel(f'{i}')\n",
    "    cont_table_ax.set_ylabel('Percentage')\n",
    "    cont_table_ax.set_title(f'Distribution of {i}\\n by Vaccine Groups')\n",
    "    cont_table_ax.legend(title='Vaccine Group')\n",
    "    \n",
    "    cont_table_ax_n.set_xlabel(f'{i}')\n",
    "    cont_table_ax_n.set_title(f'Distribution of {i}\\n by Vaccine Groups (per element)')\n",
    "    cont_table_ax_n.legend(title='Vaccine Group')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test data\n",
    "\n",
    "The same operations that we did for the training data, we will be done for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df_patients.drop(columns =['h1n1_vaccine', 'seasonal_vaccine', 'vaccine_group']).columns\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.set_index('respondent_id', inplace=True)\n",
    "test_features = test_features[columns] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float_columns = test_features.select_dtypes(include=['float64']).columns\n",
    "categorical_columns = test_features.select_dtypes(include=['object']).columns\n",
    "\n",
    "test_features[float_columns]=test_features[float_columns].fillna(-1)\n",
    "test_features[categorical_columns]=test_features[categorical_columns].fillna('missing')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "null = test_features.isnull().sum()\n",
    "\n",
    "# Calculate the percentage of missing values\n",
    "missing_percentage = (null / len(test_features)) * 100\n",
    "\n",
    "# Plot the missing values\n",
    "plt.figure(figsize=(16, 7))\n",
    "colors = ['red' if val > 20 else 'orange' for val in missing_percentage.values]\n",
    "sns.barplot(x=missing_percentage.index, y=missing_percentage.values, palette=colors, hue=missing_percentage.index, legend=False)\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Percentage of Missing Values')\n",
    "plt.xlabel('Features')\n",
    "plt.title('Percentage of Missing Values by Feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine training and test data to fit the encoder with all possible categories\n",
    "cat_features = cat_features.drop('vaccine_group')\n",
    "combined_data = pd.concat([df_patients[cat_features], test_features[categorical_columns]], axis=0)\n",
    "\n",
    "# Refit the encoder with the combined data\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "encoder = OrdinalEncoder()\n",
    "encoder.fit(combined_data)\n",
    "\n",
    "# Transform \n",
    "df_encoded = df_patients.copy()\n",
    "df_encoded.drop(columns=['vaccine_group'], inplace=True)\n",
    "df_encoded[cat_features] = encoder.transform(df_encoded[cat_features])\n",
    "test_encoded = test_features.copy()\n",
    "test_encoded[categorical_columns] = encoder.transform(test_encoded[categorical_columns])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_encoded.to_csv('data/df_encoded.csv')\n",
    "test_encoded.to_csv('data/test_encoded.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
